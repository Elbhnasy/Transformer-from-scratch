{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3136a602",
   "metadata": {},
   "source": [
    "# Transformer Model Inference\n",
    "\n",
    "This notebook demonstrates how to load a trained transformer model and use it for translation.\n",
    "We'll load the model, tokenizers, and perform inference on examples from the test set as well as custom inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48dc30e",
   "metadata": {},
   "source": [
    "## Load Model and Datasets\n",
    "\n",
    "First, we'll load the necessary components:\n",
    "- Configure the device (CPU/GPU)\n",
    "- Load configuration\n",
    "- Get datasets and tokenizers\n",
    "- Build the model\n",
    "- Load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52df765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device with proper handling for different hardware\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                     \"mps\" if torch.backends.mps.is_available() else \n",
    "                     \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load configuration\n",
    "config = get_config()\n",
    "print(f\"Source language: {config['lang_src']}\")\n",
    "print(f\"Target language: {config['lang_tgt']}\")\n",
    "print(f\"Dataset: {config['datasource']}\")\n",
    "\n",
    "try:\n",
    "    # Load datasets and tokenizers\n",
    "    print(\"Loading datasets and tokenizers...\")\n",
    "    start_time = time.time()\n",
    "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "    print(f\"Datasets loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Track vocabulary sizes for reference\n",
    "    print(f\"Source vocabulary size: {tokenizer_src.get_vocab_size():,}\")\n",
    "    print(f\"Target vocabulary size: {tokenizer_tgt.get_vocab_size():,}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Building model...\")\n",
    "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "    \n",
    "    # Count model parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {total_params:,} parameters ({trainable_params:,} trainable)\")\n",
    "    \n",
    "    # Load the pretrained weights with proper error handling\n",
    "    model_filename = latest_weights_file_path(config)\n",
    "    if model_filename and Path(model_filename).exists():\n",
    "        print(f\"Loading weights from {model_filename}\")\n",
    "        # Load weights to the correct device directly\n",
    "        state = torch.load(model_filename, map_location=device)\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        print(f\"Loaded weights from epoch {state.get('epoch', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"WARNING: No weights file found at {model_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3168d02",
   "metadata": {},
   "source": [
    "## Run Validation on Test Examples\n",
    "\n",
    "Let's evaluate our model on examples from the validation set. This helps verify that the model works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24249b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create HTML output for better visualization\n",
    "def highlight_translation(source, target, predicted):\n",
    "    return f\"\"\"\n",
    "    <div style=\"padding: 10px; margin-bottom: 10px; border: 1px solid #ddd; border-radius: 5px;\">\n",
    "        <div style=\"font-weight: bold; color: #555;\">Source:</div>\n",
    "        <div style=\"padding: 5px 10px; margin-bottom: 5px;\">{source}</div>\n",
    "        <div style=\"font-weight: bold; color: #555;\">Target:</div>\n",
    "        <div style=\"padding: 5px 10px; margin-bottom: 5px;\">{target}</div>\n",
    "        <div style=\"font-weight: bold; color: #555;\">Predicted:</div>\n",
    "        <div style=\"padding: 5px 10px; background-color: #f5f5f5;\">{predicted}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# Function to capture validation output and display in a formatted way\n",
    "validation_results = []\n",
    "def capture_validation(msg):\n",
    "    validation_results.append(msg)\n",
    "    print(msg)\n",
    "\n",
    "# Set model to evaluation mode for better inference performance\n",
    "model.eval()\n",
    "\n",
    "# Benchmark validation time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run validation with more examples (adjust as needed)\n",
    "num_examples = 10  # Increase for more thorough testing\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, \n",
    "               config['seq_len'], device, capture_validation, 0, None, \n",
    "               num_examples=num_examples)\n",
    "\n",
    "print(f\"\\nValidation completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Parse and visualize results (if available)\n",
    "current_group = {}\n",
    "all_examples = []\n",
    "\n",
    "for line in validation_results:\n",
    "    if line.startswith('SOURCE: '):\n",
    "        current_group['source'] = line[len('SOURCE: '):].strip()\n",
    "    elif line.startswith('TARGET: '):\n",
    "        current_group['target'] = line[len('TARGET: '):].strip()\n",
    "    elif line.startswith('PREDICTED: '):\n",
    "        current_group['predicted'] = line[len('PREDICTED: '):].strip()\n",
    "        if len(current_group) == 3:  # We have all components\n",
    "            all_examples.append(dict(current_group))\n",
    "            current_group = {}\n",
    "\n",
    "# Display results in a more readable format\n",
    "for example in all_examples:\n",
    "    display(HTML(highlight_translation(\n",
    "        example['source'], \n",
    "        example['target'], \n",
    "        example['predicted']\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f2a9f",
   "metadata": {},
   "source": [
    "## Translate Custom Text\n",
    "\n",
    "Now let's try translating custom text inputs. We'll use the updated `translate` function with timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e46b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced custom translation function with timing\n",
    "def translate_with_timing(text, temperature=1.0, show_details=True):\n",
    "    \"\"\"Translate text and measure performance metrics\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Translate the text\n",
    "    result = translate(text, temperature=temperature, show_progress=False)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    if show_details:\n",
    "        # Enhanced visualization\n",
    "        source_text = text\n",
    "        if isinstance(text, int) or text.isdigit():\n",
    "            source_text = f\"Example #{text} from dataset\"\n",
    "            \n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"padding: 15px; border: 1px solid #ddd; border-radius: 8px; margin: 10px 0;\">\n",
    "            <div style=\"display: flex; justify-content: space-between;\">\n",
    "                <h3 style=\"margin-top: 0;\">Translation Result</h3>\n",
    "                <div style=\"color: #888;\">Completed in {elapsed:.3f}s</div>\n",
    "            </div>\n",
    "            <div style=\"margin-bottom: 10px;\">\n",
    "                <div style=\"font-weight: bold; color: #555;\">Source ({config['lang_src']}):</div>\n",
    "                <div style=\"padding: 8px; background: #f8f8f8; border-radius: 4px;\">{source_text}</div>\n",
    "            </div>\n",
    "            <div>\n",
    "                <div style=\"font-weight: bold; color: #555;\">Translation ({config['lang_tgt']}):</div>\n",
    "                <div style=\"padding: 8px; background: #f0f7ff; border-radius: 4px; font-size: 1.1em;\">{result}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    return result, elapsed\n",
    "\n",
    "# Example 1: Translate a custom sentence with default settings\n",
    "example1, time1 = translate_with_timing(\"Why do I need to translate this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b164239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Translate using a dataset example with index\n",
    "example2, time2 = translate_with_timing(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ab1f3",
   "metadata": {},
   "source": [
    "## Translation with Different Parameters\n",
    "\n",
    "Let's explore how different parameters affect translation results and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67422cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different temperature values\n",
    "test_sentence = \"The book is on the table near the window.\"\n",
    "temperatures = [0.7, 1.0, 1.3]  # Conservative to diverse\n",
    "\n",
    "results = []\n",
    "timings = []\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\nTranslating with temperature = {temp}\")\n",
    "    result, elapsed = translate_with_timing(test_sentence, temperature=temp, show_details=False)\n",
    "    results.append(result)\n",
    "    timings.append(elapsed)\n",
    "\n",
    "# Display comparison table\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"margin: 20px 0;\">\n",
    "    <h3>Temperature Comparison</h3>\n",
    "    <p>Source: \"{test_sentence}\"</p>\n",
    "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #ddd;\">\n",
    "        <tr style=\"background-color: #f5f5f5;\">\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Temperature</th>\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Translation</th>\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Time (s)</th>\n",
    "        </tr>\n",
    "        {''.join(f'''\n",
    "        <tr>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{temp}</td>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{results[i]}</td>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{timings[i]:.3f}</td>\n",
    "        </tr>\n",
    "        ''' for i, temp in enumerate(temperatures))}\n",
    "    </table>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Plot timing comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(temperatures, timings, color='skyblue')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Translation Time vs Temperature')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624105c",
   "metadata": {},
   "source": [
    "## Batch Translation Performance\n",
    "\n",
    "Let's test batch translation performance with multiple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d78e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch translation test\n",
    "test_sentences = [\n",
    "    \"Hello, how are you today?\",\n",
    "    \"I would like to buy a train ticket to Rome.\",\n",
    "    \"The weather is beautiful this morning.\",\n",
    "    \"Can you recommend a good restaurant nearby?\",\n",
    "    \"What time does the museum open tomorrow?\"\n",
    "]\n",
    "\n",
    "# Measure total and per-sentence time\n",
    "batch_start = time.time()\n",
    "all_results = []\n",
    "individual_times = []\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    start = time.time()\n",
    "    translation = translate(sentence, show_progress=False)\n",
    "    end = time.time()\n",
    "    all_results.append(translation)\n",
    "    individual_times.append(end - start)\n",
    "    \n",
    "batch_total = time.time() - batch_start\n",
    "\n",
    "# Performance metrics\n",
    "avg_time = sum(individual_times) / len(individual_times)\n",
    "throughput = len(test_sentences) / batch_total\n",
    "\n",
    "# Display results\n",
    "print(f\"Batch translation completed in {batch_total:.2f} seconds\")\n",
    "print(f\"Average time per sentence: {avg_time:.2f} seconds\")\n",
    "print(f\"Throughput: {throughput:.2f} sentences per second\")\n",
    "\n",
    "# Show all translations in a formatted table\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"margin: 20px 0;\">\n",
    "    <h3>Batch Translation Results</h3>\n",
    "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #ddd;\">\n",
    "        <tr style=\"background-color: #f5f5f5;\">\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Source</th>\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Translation</th>\n",
    "            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Time (s)</th>\n",
    "        </tr>\n",
    "        {''.join(f'''\n",
    "        <tr>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{test_sentences[i]}</td>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{all_results[i]}</td>\n",
    "            <td style=\"padding: 8px; border: 1px solid #ddd;\">{individual_times[i]:.3f}</td>\n",
    "        </tr>\n",
    "        ''' for i in range(len(test_sentences)))}\n",
    "    </table>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Plot individual translation times\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(test_sentences)), individual_times, color='lightgreen')\n",
    "plt.axhline(y=avg_time, color='red', linestyle='--', label=f'Average: {avg_time:.2f}s')\n",
    "plt.xticks(range(len(test_sentences)), [s[:20] + '...' if len(s) > 20 else s for s in test_sentences], rotation=45)\n",
    "plt.xlabel('Sentence')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Translation Time by Sentence')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e728158",
   "metadata": {},
   "source": [
    "## Performance Optimization Notes\n",
    "\n",
    "Here are some optimization techniques that could further improve translation performance:\n",
    "\n",
    "1. **Batch Processing**: Process multiple sentences at once to better utilize GPU parallelism\n",
    "2. **Mixed Precision**: Use FP16 for faster computation on compatible GPUs\n",
    "3. **Caching**: Cache encoder outputs for repeated translations of the same source\n",
    "4. **Model Quantization**: Use quantized models (INT8) for faster inference\n",
    "5. **Beam Search**: Implement beam search for better translation quality\n",
    "6. **ONNX Export**: Export model to ONNX for runtime optimization\n",
    "7. **JIT Compilation**: Use TorchScript for compiled model execution\n",
    "\n",
    "These optimizations would require modifications to the core model code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
