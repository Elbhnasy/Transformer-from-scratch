{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d6ca4",
   "metadata": {},
   "source": [
    "# Transformer Model Local Training\n",
    "\n",
    "This notebook provides a local training interface for the transformer model with debugging and visualization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad654d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import get_config\n",
    "cfg = get_config()\n",
    "cfg['batch_size'] = 2\n",
    "cfg['preload'] = None\n",
    "cfg['num_epochs'] = 30\n",
    "\n",
    "# Print current configuration\n",
    "print(\"Current Configuration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98303c",
   "metadata": {},
   "source": [
    "## Additional Configuration Options\n",
    "\n",
    "Adjust training parameters as needed before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these parameters as needed\n",
    "cfg['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {cfg['device']}\")\n",
    "\n",
    "# Uncomment to adjust learning rate\n",
    "# cfg['lr'] = 0.0005\n",
    "\n",
    "# Uncomment to use a specific saved model\n",
    "# cfg['preload'] = 'weights/tmodel_best.pt'\n",
    "\n",
    "# Uncomment to use gradient accumulation for larger effective batch sizes\n",
    "# cfg['gradient_accumulation_steps'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b8f18",
   "metadata": {},
   "source": [
    "## Training with Visualization\n",
    "\n",
    "Execute training with progress tracking and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Create a wrapper for the train_model function with visualization\n",
    "def train_with_visualization(config):\n",
    "    from train import train_model\n",
    "    import time\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Capture training history\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    # Override the validation callback to capture metrics\n",
    "    original_callback = None\n",
    "    if 'after_validation' in config:\n",
    "        original_callback = config['after_validation']\n",
    "    \n",
    "    def visualization_callback(epoch, train_loss, val_loss, model):\n",
    "        # Append losses to history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Call original callback if it exists\n",
    "        if original_callback:\n",
    "            original_callback(epoch, train_loss, val_loss, model)\n",
    "        \n",
    "        # Plot training progress every few epochs\n",
    "        if epoch % 2 == 0 or epoch == config['num_epochs'] - 1:\n",
    "            clear_output(wait=True)\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            ax.plot(history['train_loss'], label='Training Loss')\n",
    "            ax.plot(history['val_loss'], label='Validation Loss')\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title(f'Training Progress (Epoch {epoch+1}/{config[\"num_epochs\"]})')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print current metrics\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Epoch {epoch+1}/{config['num_epochs']} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Time elapsed: {elapsed_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Set our visualization callback\n",
    "    config['after_validation'] = visualization_callback\n",
    "    \n",
    "    # Run the training\n",
    "    try:\n",
    "        model = train_model(config)\n",
    "        print(f\"\\nTraining completed in {(time.time() - start_time)/60:.2f} minutes\")\n",
    "        return model, history\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return None, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training with visualization\n",
    "model, history = train_with_visualization(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2565c",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Test the trained model with sample translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, cfg):\n",
    "    if model is None:\n",
    "        print(\"No model available for evaluation. Training may have failed.\")\n",
    "        return\n",
    "    \n",
    "    # Import necessary modules for inference\n",
    "    from dataset import get_tokenizers\n",
    "    from model import build_transformer\n",
    "    import torch\n",
    "    \n",
    "    # Get the tokenizers\n",
    "    tokenizer_src, tokenizer_tgt = get_tokenizers(cfg)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Sample sentences to translate\n",
    "    sample_sentences = [\n",
    "        \"Hello, how are you doing today?\",\n",
    "        \"I would like to book a table for dinner tonight.\",\n",
    "        \"The weather is beautiful outside.\",\n",
    "        \"Can you help me find my way to the train station?\"\n",
    "    ]\n",
    "    \n",
    "    # Translation function\n",
    "    def translate(sentence):\n",
    "        # Tokenize the source sentence\n",
    "        tokens = tokenizer_src.encode(sentence).ids\n",
    "        tokens = torch.tensor([tokens], dtype=torch.int64).to(cfg['device'])\n",
    "        \n",
    "        # Get the encoder output\n",
    "        enc_output = model.encode(tokens)\n",
    "        \n",
    "        # Initialize the decoder input with the start token\n",
    "        dec_input = torch.tensor([[tokenizer_tgt.token_to_id('[BOS]')]], dtype=torch.int64).to(cfg['device'])\n",
    "        \n",
    "        # Generate the translation token by token\n",
    "        for _ in range(100):  # Max length\n",
    "            # Get the decoder output\n",
    "            dec_output = model.decode(dec_input, enc_output, tokens)\n",
    "            prediction = dec_output[:, -1, :]  # Get the last token prediction\n",
    "            \n",
    "            # Get the token with the highest probability\n",
    "            next_token = torch.argmax(prediction, dim=-1).unsqueeze(1)\n",
    "            \n",
    "            # Append the predicted token to the decoder input\n",
    "            dec_input = torch.cat([dec_input, next_token], dim=1)\n",
    "            \n",
    "            # Check if we've generated the end token\n",
    "            if next_token.item() == tokenizer_tgt.token_to_id('[EOS]'):\n",
    "                break\n",
    "        \n",
    "        # Convert token IDs back to text\n",
    "        translation = tokenizer_tgt.decode(dec_input[0].cpu().numpy())\n",
    "        # Remove special tokens\n",
    "        translation = translation.replace('[BOS]', '').replace('[EOS]', '').strip()\n",
    "        return translation\n",
    "    \n",
    "    # Translate and print all sample sentences\n",
    "    print(f\"\\nSample translations ({cfg['lang_src']} â†’ {cfg['lang_tgt']}):\\n\")\n",
    "    for sentence in sample_sentences:\n",
    "        translation = translate(sentence)\n",
    "        print(f\"Source: {sentence}\")\n",
    "        print(f\"Translation: {translation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8eefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "if model is not None:\n",
    "    evaluate_model(model, cfg)\n",
    "else:\n",
    "    print(\"Model training failed or was not completed. Cannot perform evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e8633",
   "metadata": {},
   "source": [
    "## Debugging Tools\n",
    "\n",
    "Troubleshoot model and training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd43eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug module imports and configurations\n",
    "def debug_environment():\n",
    "    import sys\n",
    "    import torch\n",
    "    \n",
    "    print(\"Python version:\", sys.version)\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA version:\", torch.version.cuda)\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "        print(\"GPU memory allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n",
    "        print(\"GPU memory cached:\", torch.cuda.memory_reserved(0) / 1e9, \"GB\")\n",
    "    \n",
    "    print(\"\\nConfiguration:\")\n",
    "    for key, value in cfg.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Uncomment to run environment diagnostics\n",
    "# debug_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and training history\n",
    "def save_results(model, history, cfg, custom_name=None):\n",
    "    import os\n",
    "    import json\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"No model to save. Training may have failed.\")\n",
    "        return\n",
    "    \n",
    "    # Create timestamp for filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = custom_name if custom_name else f\"model_{timestamp}\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(cfg['model_folder'], exist_ok=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(cfg['model_folder'], f\"{model_name}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Save the training history\n",
    "    history_path = os.path.join(cfg['model_folder'], f\"{model_name}_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        serializable_history = {\n",
    "            'train_loss': [float(x) for x in history['train_loss']],\n",
    "            'val_loss': [float(x) for x in history['val_loss']]\n",
    "        }\n",
    "        json.dump(serializable_history, f)\n",
    "    print(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "    # Plot and save the learning curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(cfg['model_folder'], f\"{model_name}_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "    print(f\"Learning curves plot saved to {plot_path}\")\n",
    "\n",
    "# Uncomment to save your model and training history\n",
    "# save_results(model, history, cfg, custom_name=\"my_best_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
